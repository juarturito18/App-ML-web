# archivo: app.py
import streamlit as st
from sklearn.model_selection import train_test_split 
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import numpy as np
import matplotlib.pyplot as plt

#PS C:\Users\Usuario\Documents\App-ML-web\code_regresion_lineal> streamlit run test.py
#Comando para inicia el codigo 
#.\venv\Scripts\Activate.ps1 - Para activar el entorno virtual

def selector_data_training(): #Funcion para seleccionar el dataset a usar
    st.sidebar.header("Seleccionar el dataset a usar")
    datasets ={"Elige un dataset": None,
            "Precio de casa":r"C:\Users\Usuario\Documents\App-ML-web\data_regresion_lineal\housing.csv",
           "Salarios":r"C:\Users\Usuario\Documents\App-ML-web\data_regresion_lineal\Salary_dataset.csv"}
    select = st.sidebar.selectbox(
        "Elige el dataset a utilizar",
        list(datasets.keys())
    )
    upload_dataset = st.sidebar.file_uploader("Sube un archivo CSV", type=["csv", "json"])
    if datasets[select] is  None and upload_dataset is not None:
        datasets[select] = upload_dataset
    return datasets[select]

def split_data_training(): #Funci√≥n para seleccionar el porcentaje de datos a usar para training
    porcentaje = st.sidebar.slider(
        "Porcentaje de datos para entrenamiento (%)", 
        min_value=10, 
        max_value=90, 
        value=80, 
    )
    return porcentaje / 100  # Convertir a decimal (0.1 a 0.9)

def calculate_metrics(y_true, y_pred): #Funcion para calcular las metricas de evaluacion del modelo
    """Calcula todas las m√©tricas de evaluaci√≥n del modelo"""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    
    # MAPE (Mean Absolute Percentage Error) - Evitar divisi√≥n por cero
    mask = y_true != 0
    if mask.sum() > 0:
        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
    else:
        mape = np.nan
    
    return {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'R¬≤': r2,
        'MAPE': mape
    }

def show_model_metrics(y_train, y_pred_train, y_test, y_pred_test, model, target, features):
    """Funci√≥n completa para mostrar todas las m√©tricas y scores del modelo"""
    
    # Calcular m√©tricas para entrenamiento y prueba
    metrics_train = calculate_metrics(y_train, y_pred_train)
    metrics_test = calculate_metrics(y_test, y_pred_test)
    
    st.subheader("üìà M√©tricas y Scores del Modelo")
    
    # Mostrar ecuaci√≥n del modelo
    st.markdown("### Ecuaci√≥n del Modelo")
    equation = f"**{target} = {model.intercept_:.2f}**"
    for coef, feat in zip(model.coef_, features):
        sign = "+" if coef >= 0 else ""
        equation += f" {sign} {coef:.4f}¬∑{feat}"
    st.write(equation)
    
    # Mostrar m√©tricas en columnas
    st.markdown("### üìä M√©tricas de Evaluaci√≥n")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### üéØ Datos de Entrenamiento")
        st.metric("R¬≤ Score", f"{metrics_train['R¬≤']:.4f}", 
                 help="Coeficiente de determinaci√≥n. M√°s cercano a 1 es mejor.")
        st.metric("RMSE", f"{metrics_train['RMSE']:.4f}",
                 help="Ra√≠z del Error Cuadr√°tico Medio. M√°s cercano a 0 es mejor.")
        st.metric("MSE", f"{metrics_train['MSE']:.4f}",
                 help="Error Cuadr√°tico Medio. M√°s cercano a 0 es mejor.")
        st.metric("MAE", f"{metrics_train['MAE']:.4f}",
                 help="Error Absoluto Medio. M√°s cercano a 0 es mejor.")
        if not np.isnan(metrics_train['MAPE']):
            st.metric("MAPE", f"{metrics_train['MAPE']:.2f}%",
                     help="Error Porcentual Absoluto Medio. M√°s cercano a 0% es mejor.")
        else:
            st.metric("MAPE", "N/A", help="No se puede calcular (valores cero en datos)")
    
    with col2:
        st.markdown("#### üß™ Datos de Prueba")
        st.metric("R¬≤ Score", f"{metrics_test['R¬≤']:.4f}",
                 help="Coeficiente de determinaci√≥n. M√°s cercano a 1 es mejor.")
        st.metric("RMSE", f"{metrics_test['RMSE']:.4f}",
                 help="Ra√≠z del Error Cuadr√°tico Medio. M√°s cercano a 0 es mejor.")
        st.metric("MSE", f"{metrics_test['MSE']:.4f}",
                 help="Error Cuadr√°tico Medio. M√°s cercano a 0 es mejor.")
        st.metric("MAE", f"{metrics_test['MAE']:.4f}",
                 help="Error Absoluto Medio. M√°s cercano a 0 es mejor.")
        if not np.isnan(metrics_test['MAPE']):
            st.metric("MAPE", f"{metrics_test['MAPE']:.2f}%",
                     help="Error Porcentual Absoluto Medio. M√°s cercano a 0% es mejor.")
        else:
            st.metric("MAPE", "N/A", help="No se puede calcular (valores cero en datos)")
    
    # Comparaci√≥n de rendimiento
    st.markdown("### üîç An√°lisis de Rendimiento")
    
    # Diferencia entre entrenamiento y prueba
    diff_r2 = metrics_train['R¬≤'] - metrics_test['R¬≤']
    diff_rmse = metrics_test['RMSE'] - metrics_train['RMSE']
    
    col3, col4 = st.columns(2)
    
    with col3:
        if diff_r2 < 0.05:
            st.success(f"‚úÖ **Buen ajuste:** La diferencia en R¬≤ entre entrenamiento y prueba es {diff_r2:.4f}. El modelo generaliza bien.")
        elif diff_r2 < 0.15:
            st.warning(f"‚ö†Ô∏è **Ajuste moderado:** La diferencia en R¬≤ es {diff_r2:.4f}. El modelo puede estar sobreajust√°ndose ligeramente.")
        else:
            st.error(f"‚ùå **Sobreajuste:** La diferencia en R¬≤ es {diff_r2:.4f}. El modelo est√° memorizando los datos de entrenamiento.")
    
    with col4:
        if metrics_test['R¬≤'] > 0.8:
            st.success(f"‚úÖ **Excelente modelo:** R¬≤ de prueba = {metrics_test['R¬≤']:.4f}")
        elif metrics_test['R¬≤'] > 0.6:
            st.info(f"‚ÑπÔ∏è **Modelo aceptable:** R¬≤ de prueba = {metrics_test['R¬≤']:.4f}")
        else:
            st.warning(f"‚ö†Ô∏è **Modelo mejorable:** R¬≤ de prueba = {metrics_test['R¬≤']:.4f}. Considera revisar las variables o el modelo.")
    
    # Tabla comparativa
    st.markdown("### üìã Tabla Comparativa de M√©tricas")
    comparison_df = pd.DataFrame({
        'M√©trica': ['R¬≤ Score', 'RMSE', 'MSE', 'MAE', 'MAPE (%)'],
        'Entrenamiento': [
            f"{metrics_train['R¬≤']:.4f}",
            f"{metrics_train['RMSE']:.4f}",
            f"{metrics_train['MSE']:.4f}",
            f"{metrics_train['MAE']:.4f}",
            f"{metrics_train['MAPE']:.2f}%" if not np.isnan(metrics_train['MAPE']) else "N/A"
        ],
        'Prueba': [
            f"{metrics_test['R¬≤']:.4f}",
            f"{metrics_test['RMSE']:.4f}",
            f"{metrics_test['MSE']:.4f}",
            f"{metrics_test['MAE']:.4f}",
            f"{metrics_test['MAPE']:.2f}%" if not np.isnan(metrics_test['MAPE']) else "N/A"
        ],
        'Diferencia': [
            f"{diff_r2:.4f}",
            f"{diff_rmse:.4f}",
            f"{metrics_test['MSE'] - metrics_train['MSE']:.4f}",
            f"{metrics_test['MAE'] - metrics_train['MAE']:.4f}",
            f"{metrics_test['MAPE'] - metrics_train['MAPE']:.2f}%" if not (np.isnan(metrics_test['MAPE']) or np.isnan(metrics_train['MAPE'])) else "N/A"
        ]
    })
    st.dataframe(comparison_df, use_container_width=True, hide_index=True)
    
    # Explicaci√≥n de m√©tricas
    with st.expander("üìö ¬øQu√© significan estas m√©tricas?"):
        st.markdown("""
        - **R¬≤ Score (Coeficiente de Determinaci√≥n):** 
          - Rango: 0 a 1 (puede ser negativo si el modelo es muy malo)
          - Indica qu√© tan bien el modelo explica la variabilidad de los datos
          - **1.0 = Perfecto** | **>0.8 = Excelente** | **>0.6 = Bueno** | **<0.5 = Mejorable**
        
        - **RMSE (Ra√≠z del Error Cuadr√°tico Medio):**
          - Mide el error promedio en las mismas unidades que la variable objetivo
          - Penaliza m√°s los errores grandes
          - **M√°s cercano a 0 = Mejor**
        
        - **MSE (Error Cuadr√°tico Medio):**
          - Similar al RMSE pero en unidades cuadradas
          - Penaliza mucho los errores grandes
          - **M√°s cercano a 0 = Mejor**
        
        - **MAE (Error Absoluto Medio):**
          - Error promedio en valor absoluto
          - No penaliza tanto los errores grandes como MSE/RMSE
          - **M√°s cercano a 0 = Mejor**
        
        - **MAPE (Error Porcentual Absoluto Medio):**
          - Error expresado como porcentaje
          - √ötil para comparar modelos con diferentes escalas
          - **M√°s cercano a 0% = Mejor**
        """)

def show_results_model(X_train, y_train, X_test, y_test, model, target, features, tipo="ambos"): 
    """Funci√≥n para calcular predicciones y retornarlas (mantiene compatibilidad)"""
    if tipo == "entrenamiento" or tipo == "ambos":
        y_pred_train = model.predict(X_train)
    
    if tipo == "prueba" or tipo == "ambos":
        y_pred_test = model.predict(X_test)
    
    if tipo == "ambos":
        return y_pred_train, y_pred_test
    elif tipo == "entrenamiento":
        return y_pred_train
    else:
        return y_pred_test

def show_graph_variables(X_train, y_train, X_test, y_test, y_pred_train, y_pred_test, target, features):
    if len(features) == 1:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
        # Gr√°fico de entrenamiento
        ax1.scatter(X_train, y_train, color="blue", alpha=0.6, label="Datos reales")
        ax1.plot(X_train, y_pred_train, color="red", linewidth=2, label="Predicci√≥n")
        ax1.set_xlabel(features[0])
        ax1.set_ylabel(target)
        ax1.set_title("üìä Datos de Entrenamiento")
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # Gr√°fico de prueba
        ax2.scatter(X_test, y_test, color="green", alpha=0.6, label="Datos reales")
        ax2.plot(X_test, y_pred_test, color="orange", linewidth=2, label="Predicci√≥n")
        ax2.set_xlabel(features[0])
        ax2.set_ylabel(target)
        ax2.set_title("üß™ Datos de Prueba")
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        st.pyplot(fig)
        
        st.markdown("""
        **Explicaci√≥n de los gr√°ficos:**
        - **Gr√°fico izquierdo (Entrenamiento):** Muestra c√≥mo el modelo se ajusta a los datos con los que fue entrenado
        - **Gr√°fico derecho (Prueba):** Muestra c√≥mo el modelo predice datos que nunca ha visto. 
          Si el modelo generaliza bien, ambos gr√°ficos deber√≠an verse similares.
        """)

st.title("üìä Regresi√≥n Lineal Interactiva")

st.markdown("La **regresi√≥n lineal** es uno de los algoritmos m√°s simples y fundamentales en el aprendizaje autom√°tico. " \
"Su objetivo es encontrar la relaci√≥n entre una o m√°s variables independientes y una variable dependiente, ajustando una l√≠nea recta que mejor represente los datos." \
" Gracias a su facilidad de interpretaci√≥n y aplicaci√≥n, la regresi√≥n lineal es ideal para comprender los conceptos b√°sicos de modelado predictivo y sentar las bases para algoritmos m√°s complejos.")

# 1. Cargar datos

datasets = selector_data_training()

uploaded_file = datasets

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
else:
    st.info("Sube un archivo CSV para comenzar")
    st.stop()

st.write("### Vista previa de los datos")

df_edit = st.data_editor(df)

st.markdown("Lo primero a analizar de nuestro conjunto de datos o dataset, es saber cual es nuestra ***variable objetivo*** " \
"y nuestra ***variable predictora***, esto porque nuestro objetivo es predecir el comportamiento de nuestra variable " \
"en base a las condiciones que tenga la variable predictora y a si tener una linea de predicci√≥n.")
st.info("Selecciona las variables que deseas analizar y el porcentaje de datos para entrenamiento")

# 2. Seleccionar variables
target = st.sidebar.selectbox("Variable objetivo (Y)", df_edit.columns)
features = st.sidebar.multiselect("Variables predictoras (X)", df_edit.columns, default=[col for col in df_edit.columns if col != target])

# 2.1. Configuraci√≥n de divisi√≥n de datos
st.sidebar.header("‚öôÔ∏è Configuraci√≥n del Modelo")
porcentaje_train = split_data_training()

if not features:
    st.warning("Selecciona al menos una variable predictora")
    st.stop()

if len(features) == 1:
    plt.scatter(df_edit[features], df_edit[target], color="blue")
    plt.xlabel(features[0])
    plt.ylabel(target)
    st.pyplot(plt)

st.markdown(f"""A primera vista como observamos en este grafico con solo los datos, 
podemos ver que existe una **relaci√≥n** entre nuestras variables donde son directamente proporcionas donde podemos
que nuestra variable objetivo: **'{target}'**, tiene una cierta relaci√≥n con nuestra variable predictora **'{features[0]}**'
""")
# 3. Preparar datos y dividir en entrenamiento y prueba
X = df_edit[features]
y = df_edit[target]

# Dividir datos usando train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=1 - porcentaje_train,  # El complemento del porcentaje de entrenamiento
    random_state=42  # Semilla para reproducibilidad
)

# Mostrar informaci√≥n de la divisi√≥n
st.info(f"üìä **Divisi√≥n de datos:** {len(X_train)} registros para entrenamiento ({porcentaje_train*100:.0f}%) | {len(X_test)} registros para prueba ({(1-porcentaje_train)*100:.0f}%)")

# 4. Entrenar modelo SOLO con datos de entrenamiento
model = LinearRegression()
model.fit(X_train, y_train)

st.subheader("Entrenar al modelo")
model_train = f"""
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size={1 - porcentaje_train:.2f},  # {(1-porcentaje_train)*100:.0f}% para prueba
    random_state=42
)

model = LinearRegression()
model.fit(X_train, y_train)  # Entrenar SOLO con datos de entrenamiento
"""
st.code(model_train)

st.markdown(f""" Luego de definir cual es nuestra intenci√≥n por la que vamos a analizar las variables
            tenemos que **dividir nuestros datos** entre entrenamiento y prueba. Esto es importante porque
            necesitamos datos que el modelo nunca haya visto para evaluar su rendimiento real.
            
            Despu√©s, entrenamos el modelo con **'model.fit(X_train, y_train)'** usando SOLO los datos de entrenamiento.
            Esto permite que el modelo aprenda los patrones sin "memorizar" los datos.
""")

# 5. Calcular predicciones
y_pred_train, y_pred_test = show_results_model(X_train, y_train, X_test, y_test, model, target, features, tipo="ambos")

# 6. Mostrar m√©tricas completas del modelo
show_model_metrics(y_train, y_pred_train, y_test, y_pred_test, model, target, features)

# 7. Visualizaci√≥n si es una sola variable
show_graph_variables(X_train, y_train, X_test, y_test, y_pred_train, y_pred_test, target, features)
